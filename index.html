<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>1d790928a49b4462908453248fe1b1f3</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section
id="an-analysis-of-socioeconomic-factors-contributing-to-mental-health-disorders-around-the-world"
class="cell markdown">
<h1>An Analysis of Socioeconomic Factors Contributing to Mental Health
Disorders Around the World</h1>
</section>
<div class="cell markdown">
<p>By: Olivia Reese</p>
</div>
<div class="cell markdown">
<p><strong>Introduction</strong></p>
</div>
<div class="cell markdown">
<p><strong>Mental Health Significance</strong></p>
<p>Mental health is one of the key components toward overall well-being,
as it influences an individual's quality of life. Despite its
significance, mental health disorders are a global challenge that are
seemingly worsening throughout the years. A CNN/Kaiser Family Foundation
poll recently reported that "90% of Americans feel that we are in a
mental health crisis". There are a variety of factors contributing to
mental health disorders, and vary from individual to individual.
However, trends exist on a country level such as econimic indicators,
demographics, etc, that make individuals more susceptible to mental
health disorders. Gaining an understanding of these factors that
influence mental health and developing effective preventive strategies
are highly valued for worldwide health initiatives.</p>
<p>More information regarding mental health can be found at the World
Health Organization (WHO) website: <a
href="https://www.who.int/news-room/fact-sheets/detail/mental-health-strengthening-our-response"
class="uri">https://www.who.int/news-room/fact-sheets/detail/mental-health-strengthening-our-response</a></p>
</div>
<div class="cell markdown">
<p><strong>Purpose</strong></p>
<p>The purpose of this study is to analyze mental health disorders
around the world and contribute toward developing predictive models for
mental health on a global scale. Various factors that potentially
influence mental health disorders around the world will be analyzed,
such as demographics, economic indicators, and more. This study will use
statistical analysis and machine learning techniques in order to gain
insight toward the patterns of mental health disorders, and attempt to
predict countries' susceptibilities to mental health disorders.</p>
<p>This study is especially applicable to data science because it aims
to address the very complex nature of mental health disorders around the
world through using statistical analysis and machine learning
techniques. By understanding the factors that contribute toward mental
health disorders, people such as healthcare professionals and
policymakers can design preventive strategies for specific populations
that are susceptible to mental health disorders. From this, the burden
of mental health disorders may be mitigated and overall improve the
well-being of individuals around the world.</p>
</div>
<div class="cell markdown">
<p><strong>Part 1: Data Collection</strong></p>
</div>
<div class="cell markdown">
<p>This section includes the functionality for collecting all relevant
data for this study. First, all Python libraries are imported here for
the study.</p>
</div>
<div class="cell code" data-execution_count="219">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> <span class="bu">reduce</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Factors typically not studied that could potentially influence mental
health throughout the world include:</p>
<ul>
<li>Population density</li>
<li>GDP per capita</li>
<li>Unemployment percentage</li>
<li>Life expectancy</li>
<li>Healthcare expenditure</li>
</ul>
</div>
<div class="cell markdown">
<p>Data sources:</p>
<ul>
<li>Mental health dataset by country: <a
href="https://www.kaggle.com/datasets/thedevastator/uncover-global-trends-in-mental-health-disorder"
class="uri">https://www.kaggle.com/datasets/thedevastator/uncover-global-trends-in-mental-health-disorder</a></li>
<li>Population dataset by country: <a
href="https://www.kaggle.com/datasets/chandanchoudhury/world-population-dataset?select=world_population_by_year_1950_2023.csv"
class="uri">https://www.kaggle.com/datasets/chandanchoudhury/world-population-dataset?select=world_population_by_year_1950_2023.csv</a></li>
<li>GDP dataset by country: <a
href="https://www.kaggle.com/datasets/tmishinev/world-country-gdp-19602021"
class="uri">https://www.kaggle.com/datasets/tmishinev/world-country-gdp-19602021</a></li>
<li>Unemployment dataset by country: <a
href="https://www.kaggle.com/datasets/pantanjali/unemployment-dataset"
class="uri">https://www.kaggle.com/datasets/pantanjali/unemployment-dataset</a></li>
<li>Healthcare expenditure and life exepctancy by country: <a
href="https://www.kaggle.com/datasets/mjshri23/life-expectancy-and-socio-economic-world-bank"
class="uri">https://www.kaggle.com/datasets/mjshri23/life-expectancy-and-socio-economic-world-bank</a></li>
</ul>
</div>
<div class="cell markdown">
<p><strong>Gathering Data</strong></p>
<p>The factors (independent variables) analyzed in this study are
population density, GDP per capita, unemployment, healthcare
expenditure, and life expectancy. The following demonstrates how the
data is gathered, which will be reading from a csv file of each dataset
listed above and storing the result in a DataFrame.</p>
</div>
<div class="cell markdown">
<p>Mental health data</p>
<p>This DataFrame will include mental health information (schizophrenia
%, bipolar disorder %, eating disorders %, anxiety disorders %, drug use
disorders %, depression %, and alcohol use disorders %) for each country
for the years of 1990 through 2017.</p>
</div>
<div class="cell code" data-execution_count="220">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mental_health_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/Mental health Depression disorder Data.csv&quot;</span>, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>mental_health_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="220">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>Entity</th>
      <th>Code</th>
      <th>Year</th>
      <th>Schizophrenia (%)</th>
      <th>Bipolar disorder (%)</th>
      <th>Eating disorders (%)</th>
      <th>Anxiety disorders (%)</th>
      <th>Drug use disorders (%)</th>
      <th>Depression (%)</th>
      <th>Alcohol use disorders (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1990</td>
      <td>0.16056</td>
      <td>0.697779</td>
      <td>0.101855</td>
      <td>4.828830</td>
      <td>1.677082</td>
      <td>4.071831</td>
      <td>0.672404</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1991</td>
      <td>0.160312</td>
      <td>0.697961</td>
      <td>0.099313</td>
      <td>4.829740</td>
      <td>1.684746</td>
      <td>4.079531</td>
      <td>0.671768</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1992</td>
      <td>0.160135</td>
      <td>0.698107</td>
      <td>0.096692</td>
      <td>4.831108</td>
      <td>1.694334</td>
      <td>4.088358</td>
      <td>0.670644</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1993</td>
      <td>0.160037</td>
      <td>0.698257</td>
      <td>0.094336</td>
      <td>4.830864</td>
      <td>1.705320</td>
      <td>4.096190</td>
      <td>0.669738</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1994</td>
      <td>0.160022</td>
      <td>0.698469</td>
      <td>0.092439</td>
      <td>4.829423</td>
      <td>1.716069</td>
      <td>4.099582</td>
      <td>0.669260</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Population data</p>
<p>Two DataFrames are created here, one for global country statistics,
and the other for population of each country from the years 1950 through
2023. These datasets will be used in conjunction in order to determine
the population density for each country in this range of years.</p>
</div>
<div class="cell code" data-execution_count="221">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>country_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_country_stats.csv&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>country_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="221">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>region</th>
      <th>land_area</th>
      <th>fertility_rate</th>
      <th>median_age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>Asia</td>
      <td>652860</td>
      <td>4.4</td>
      <td>17.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>Europe</td>
      <td>27400</td>
      <td>1.4</td>
      <td>38.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>Africa</td>
      <td>2381740</td>
      <td>2.8</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>American Samoa</td>
      <td>Oceania</td>
      <td>200</td>
      <td>2.2</td>
      <td>29.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Andorra</td>
      <td>Europe</td>
      <td>470</td>
      <td>1.1</td>
      <td>43.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="222">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>population_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_population_by_year_1950_2023.csv&quot;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>population_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="222">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>...</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
      <th>2023</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>7480461</td>
      <td>7571537</td>
      <td>7667533</td>
      <td>7764546</td>
      <td>7864285</td>
      <td>7971931</td>
      <td>8087727</td>
      <td>8210201</td>
      <td>8333826</td>
      <td>...</td>
      <td>32716210</td>
      <td>33753499</td>
      <td>34636207</td>
      <td>35643418</td>
      <td>36686784</td>
      <td>37769499</td>
      <td>38972230</td>
      <td>40099462</td>
      <td>41128771</td>
      <td>42239854</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>1252582</td>
      <td>1289168</td>
      <td>1326948</td>
      <td>1366744</td>
      <td>1409005</td>
      <td>1453730</td>
      <td>1500624</td>
      <td>1549571</td>
      <td>1600983</td>
      <td>...</td>
      <td>2884102</td>
      <td>2882481</td>
      <td>2881063</td>
      <td>2879355</td>
      <td>2877013</td>
      <td>2873883</td>
      <td>2866849</td>
      <td>2854710</td>
      <td>2842321</td>
      <td>2832439</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>9019866</td>
      <td>9271734</td>
      <td>9521702</td>
      <td>9771686</td>
      <td>10011541</td>
      <td>10242288</td>
      <td>10473168</td>
      <td>10703251</td>
      <td>10933784</td>
      <td>...</td>
      <td>38760168</td>
      <td>39543154</td>
      <td>40339329</td>
      <td>41136546</td>
      <td>41927007</td>
      <td>42705368</td>
      <td>43451666</td>
      <td>44177969</td>
      <td>44903225</td>
      <td>45606480</td>
    </tr>
    <tr>
      <th>3</th>
      <td>American Samoa</td>
      <td>19032</td>
      <td>19425</td>
      <td>19561</td>
      <td>19670</td>
      <td>19758</td>
      <td>19826</td>
      <td>19902</td>
      <td>19937</td>
      <td>19918</td>
      <td>...</td>
      <td>52217</td>
      <td>51368</td>
      <td>50448</td>
      <td>49463</td>
      <td>48424</td>
      <td>47321</td>
      <td>46189</td>
      <td>45035</td>
      <td>44273</td>
      <td>43914</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Andorra</td>
      <td>6005</td>
      <td>5827</td>
      <td>5454</td>
      <td>5308</td>
      <td>5566</td>
      <td>6116</td>
      <td>6705</td>
      <td>7330</td>
      <td>7994</td>
      <td>...</td>
      <td>71621</td>
      <td>71746</td>
      <td>72540</td>
      <td>73837</td>
      <td>75013</td>
      <td>76343</td>
      <td>77700</td>
      <td>79034</td>
      <td>79824</td>
      <td>80088</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 75 columns</p>
</div>
</div>
</div>
<div class="cell markdown">
<p>GDP per capita data</p>
<p>This DataFrame will contain the GDP per capita in USD for each
country between the years 1960 and 2021.</p>
</div>
<div class="cell code" data-execution_count="223">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_country_gdp_usd.csv&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>gdp_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="223">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Country Code</th>
      <th>year</th>
      <th>GDP_USD</th>
      <th>GDP_per_capita_USD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Aruba</td>
      <td>ABW</td>
      <td>1960</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Africa Eastern and Southern</td>
      <td>AFE</td>
      <td>1960</td>
      <td>2.129059e+10</td>
      <td>162.726326</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>1960</td>
      <td>5.377778e+08</td>
      <td>59.773234</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Africa Western and Central</td>
      <td>AFW</td>
      <td>1960</td>
      <td>1.040414e+10</td>
      <td>107.930722</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Angola</td>
      <td>AGO</td>
      <td>1960</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Unemployment data</p>
<p>This DataFrame includes the percentage of individuals in each country
that were unemployed in each year from 1991 through 2021.</p>
</div>
<div class="cell code" data-execution_count="224">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/unemployment analysis.csv&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>unemployment_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="224">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Country Code</th>
      <th>1991</th>
      <th>1992</th>
      <th>1993</th>
      <th>1994</th>
      <th>1995</th>
      <th>1996</th>
      <th>1997</th>
      <th>1998</th>
      <th>...</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Africa Eastern and Southern</td>
      <td>AFE</td>
      <td>7.80</td>
      <td>7.84</td>
      <td>7.85</td>
      <td>7.84</td>
      <td>7.83</td>
      <td>7.84</td>
      <td>7.86</td>
      <td>7.81</td>
      <td>...</td>
      <td>6.56</td>
      <td>6.45</td>
      <td>6.41</td>
      <td>6.49</td>
      <td>6.61</td>
      <td>6.71</td>
      <td>6.73</td>
      <td>6.91</td>
      <td>7.56</td>
      <td>8.11</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>10.65</td>
      <td>10.82</td>
      <td>10.72</td>
      <td>10.73</td>
      <td>11.18</td>
      <td>10.96</td>
      <td>10.78</td>
      <td>10.80</td>
      <td>...</td>
      <td>11.34</td>
      <td>11.19</td>
      <td>11.14</td>
      <td>11.13</td>
      <td>11.16</td>
      <td>11.18</td>
      <td>11.15</td>
      <td>11.22</td>
      <td>11.71</td>
      <td>13.28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Africa Western and Central</td>
      <td>AFW</td>
      <td>4.42</td>
      <td>4.53</td>
      <td>4.55</td>
      <td>4.54</td>
      <td>4.53</td>
      <td>4.57</td>
      <td>4.60</td>
      <td>4.66</td>
      <td>...</td>
      <td>4.64</td>
      <td>4.41</td>
      <td>4.69</td>
      <td>4.63</td>
      <td>5.57</td>
      <td>6.02</td>
      <td>6.04</td>
      <td>6.06</td>
      <td>6.77</td>
      <td>6.84</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Angola</td>
      <td>AGO</td>
      <td>4.21</td>
      <td>4.21</td>
      <td>4.23</td>
      <td>4.16</td>
      <td>4.11</td>
      <td>4.10</td>
      <td>4.09</td>
      <td>4.07</td>
      <td>...</td>
      <td>7.35</td>
      <td>7.37</td>
      <td>7.37</td>
      <td>7.39</td>
      <td>7.41</td>
      <td>7.41</td>
      <td>7.42</td>
      <td>7.42</td>
      <td>8.33</td>
      <td>8.53</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Albania</td>
      <td>ALB</td>
      <td>10.31</td>
      <td>30.01</td>
      <td>25.26</td>
      <td>20.84</td>
      <td>14.61</td>
      <td>13.93</td>
      <td>16.88</td>
      <td>20.05</td>
      <td>...</td>
      <td>13.38</td>
      <td>15.87</td>
      <td>18.05</td>
      <td>17.19</td>
      <td>15.42</td>
      <td>13.62</td>
      <td>12.30</td>
      <td>11.47</td>
      <td>13.33</td>
      <td>11.82</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 33 columns</p>
</div>
</div>
</div>
<div class="cell markdown">
<p>Healthcare expenditure and life expectancy data</p>
<p>The following dataframe will contain information regarding each
country's healthcare expenditure expressed as a percentage of their GDP,
unemployment %, etc, from 2001 through 2019.</p>
</div>
<div class="cell code" data-execution_count="225">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># healthcare expenditure dataset (has healthcare expenditure %, education expenditure %, unemployment %, country&#39;s income group, etc)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/life expectancy.csv&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>expenditure_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="225">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Country Code</th>
      <th>Region</th>
      <th>IncomeGroup</th>
      <th>Year</th>
      <th>Life Expectancy World Bank</th>
      <th>Prevelance of Undernourishment</th>
      <th>CO2</th>
      <th>Health Expenditure %</th>
      <th>Education Expenditure %</th>
      <th>Unemployment</th>
      <th>Corruption</th>
      <th>Sanitation</th>
      <th>Injuries</th>
      <th>Communicable</th>
      <th>NonCommunicable</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>AFG</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>2001</td>
      <td>56.308</td>
      <td>47.8</td>
      <td>730.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>10.809000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2179727.10</td>
      <td>9689193.70</td>
      <td>5795426.38</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Angola</td>
      <td>AGO</td>
      <td>Sub-Saharan Africa</td>
      <td>Lower middle income</td>
      <td>2001</td>
      <td>47.059</td>
      <td>67.5</td>
      <td>15960.0</td>
      <td>4.483516</td>
      <td>NaN</td>
      <td>4.004000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1392080.71</td>
      <td>11190210.53</td>
      <td>2663516.34</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Albania</td>
      <td>ALB</td>
      <td>Europe &amp; Central Asia</td>
      <td>Upper middle income</td>
      <td>2001</td>
      <td>74.288</td>
      <td>4.9</td>
      <td>3230.0</td>
      <td>7.139524</td>
      <td>3.4587</td>
      <td>18.575001</td>
      <td>NaN</td>
      <td>40.520895</td>
      <td>117081.67</td>
      <td>140894.78</td>
      <td>532324.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Andorra</td>
      <td>AND</td>
      <td>Europe &amp; Central Asia</td>
      <td>High income</td>
      <td>2001</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>520.0</td>
      <td>5.865939</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>21.788660</td>
      <td>1697.99</td>
      <td>695.56</td>
      <td>13636.64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>United Arab Emirates</td>
      <td>ARE</td>
      <td>Middle East &amp; North Africa</td>
      <td>High income</td>
      <td>2001</td>
      <td>74.544</td>
      <td>2.8</td>
      <td>97200.0</td>
      <td>2.484370</td>
      <td>NaN</td>
      <td>2.493000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>144678.14</td>
      <td>65271.91</td>
      <td>481740.70</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p><strong>Part 2: Data Processing/Cleaning</strong></p>
<p>After the data has been collected, it must be properly formatted and
cleaned in order to be merged for later processing.</p>
</div>
<div class="cell markdown">
<p>Mental health data</p>
</div>
<div class="cell markdown">
<p>The mental health dataset will need to be cleaned as to drop all
irrelevant rows and columns from the table, as well as typecasting the
columns to their proper types. The 'Entity' column will be renamed to
"Country Name" to remain consistent along all dataframes for later
merging. Furthermore, the rows will need to be reduced so that only
years from 2001-2017 are in the table.</p>
</div>
<div class="cell code" data-execution_count="226">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping useless info from table </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>mental_health_data <span class="op">=</span> mental_health_data.drop(index<span class="op">=</span>mental_health_data.index[<span class="dv">6468</span>:])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># typecasting columns to correct types </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>mental_health_data[<span class="st">&#39;Year&#39;</span>] <span class="op">=</span> mental_health_data[<span class="st">&#39;Year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>mental_health_data[<span class="st">&#39;Schizophrenia (%)&#39;</span>] <span class="op">=</span> mental_health_data[<span class="st">&#39;Schizophrenia (%)&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>mental_health_data[<span class="st">&#39;Bipolar disorder (%)&#39;</span>] <span class="op">=</span> mental_health_data[<span class="st">&#39;Bipolar disorder (%)&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>mental_health_data[<span class="st">&#39;Eating disorders (%)&#39;</span>] <span class="op">=</span> mental_health_data[<span class="st">&#39;Eating disorders (%)&#39;</span>].astype(<span class="bu">float</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years not used in the study (only 2001-2017)</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>mental_health_data <span class="op">=</span> mental_health_data[(mental_health_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2001</span>) <span class="op">&amp;</span> (mental_health_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping columns irrelevant to study </span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>mental_health_data <span class="op">=</span> mental_health_data.drop(columns<span class="op">=</span>[<span class="st">&#39;index&#39;</span>, <span class="st">&#39;Code&#39;</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># renaming &#39;Entity&#39; column to &#39;Country Name&#39;</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>mental_health_data <span class="op">=</span> mental_health_data.rename(columns<span class="op">=</span>{<span class="st">&#39;Entity&#39;</span>: <span class="st">&#39;Country Name&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="227">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>mental_health_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="227">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Year</th>
      <th>Schizophrenia (%)</th>
      <th>Bipolar disorder (%)</th>
      <th>Eating disorders (%)</th>
      <th>Anxiety disorders (%)</th>
      <th>Drug use disorders (%)</th>
      <th>Depression (%)</th>
      <th>Alcohol use disorders (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>11</th>
      <td>Afghanistan</td>
      <td>2001</td>
      <td>0.161957</td>
      <td>0.700499</td>
      <td>0.086517</td>
      <td>4.831409</td>
      <td>1.839123</td>
      <td>4.121381</td>
      <td>0.661158</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Afghanistan</td>
      <td>2002</td>
      <td>0.162414</td>
      <td>0.701141</td>
      <td>0.087023</td>
      <td>4.838318</td>
      <td>1.934326</td>
      <td>4.124928</td>
      <td>0.659213</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Afghanistan</td>
      <td>2003</td>
      <td>0.162916</td>
      <td>0.701860</td>
      <td>0.087189</td>
      <td>4.845538</td>
      <td>2.051106</td>
      <td>4.125230</td>
      <td>0.657354</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Afghanistan</td>
      <td>2004</td>
      <td>0.163377</td>
      <td>0.702556</td>
      <td>0.088158</td>
      <td>4.851512</td>
      <td>2.163044</td>
      <td>4.126384</td>
      <td>0.656132</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Afghanistan</td>
      <td>2005</td>
      <td>0.163706</td>
      <td>0.703078</td>
      <td>0.088933</td>
      <td>4.854684</td>
      <td>2.247443</td>
      <td>4.126908</td>
      <td>0.655686</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Population data</p>
<p>The population data currently is in a format such that there is a
column for the country name, as well as columns for each year in the
table (1950-2023) with its values being the population. In order for
this table to be in a tidy format, the data should be reshaped using
melting so that the columns are country, year, and population.</p>
</div>
<div class="cell code" data-execution_count="228">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># melting the population data to reshape it </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>global_population_data <span class="op">=</span> population_data.melt(id_vars<span class="op">=</span>[<span class="st">&#39;country&#39;</span>], var_name<span class="op">=</span><span class="st">&#39;year&#39;</span>, value_name<span class="op">=</span><span class="st">&#39;population&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>From here, we will need to calculate the population density for each
country during this time frame. The 'country_data' dataframe will be
used in conjunction with this 'global_population_data' dataframe, as it
contains relevant information such as the land area (in km^2) for each
country. The two dataframes will first be merged on the country name and
then a new column will be created which calculates the population / land
area for each country.</p>
</div>
<div class="cell code" data-execution_count="229">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># merge both dataframes on the &#39;country&#39; column</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> pd.merge(global_population_data, country_data, on<span class="op">=</span><span class="st">&#39;country&#39;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># creating &#39;population_density&#39; column</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>density_data[<span class="st">&#39;population_density&#39;</span>] <span class="op">=</span> density_data[<span class="st">&#39;population&#39;</span>] <span class="op">/</span> density_data[<span class="st">&#39;land_area&#39;</span>]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>density_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="229">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>year</th>
      <th>population</th>
      <th>region</th>
      <th>land_area</th>
      <th>fertility_rate</th>
      <th>median_age</th>
      <th>population_density</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>1950</td>
      <td>7480461</td>
      <td>Asia</td>
      <td>652860</td>
      <td>4.4</td>
      <td>17.0</td>
      <td>11.457986</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>1950</td>
      <td>1252582</td>
      <td>Europe</td>
      <td>27400</td>
      <td>1.4</td>
      <td>38.0</td>
      <td>45.714672</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>1950</td>
      <td>9019866</td>
      <td>Africa</td>
      <td>2381740</td>
      <td>2.8</td>
      <td>28.0</td>
      <td>3.787091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>American Samoa</td>
      <td>1950</td>
      <td>19032</td>
      <td>Oceania</td>
      <td>200</td>
      <td>2.2</td>
      <td>29.0</td>
      <td>95.160000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Andorra</td>
      <td>1950</td>
      <td>6005</td>
      <td>Europe</td>
      <td>470</td>
      <td>1.1</td>
      <td>43.0</td>
      <td>12.776596</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Finally, the year column is typecasted to an int, and all years not
within the range of 2001-2017 are dropped. Furthermore, irrelevant
columns in the table are dropped for this study. The 'country' and
'year' columns will also be renamed to remain consistent with the
above.</p>
</div>
<div class="cell code" data-execution_count="230">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># typecasting year to correct int</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>density_data[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> density_data[<span class="st">&#39;year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years not used in the study (only 2001-2017)</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>density_data[(density_data[<span class="st">&#39;year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2001</span>) <span class="op">&amp;</span> (density_data[<span class="st">&#39;year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study </span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> density_data.drop(columns<span class="op">=</span>[<span class="st">&#39;population&#39;</span>, <span class="st">&#39;land_area&#39;</span>, <span class="st">&#39;fertility_rate&#39;</span>, <span class="st">&#39;median_age&#39;</span>, <span class="st">&#39;region&#39;</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># renaming &#39;country&#39; to &#39;Country Name&#39; and &#39;year&#39; to &#39;Year&#39;</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> density_data.rename(columns<span class="op">=</span>{<span class="st">&#39;country&#39;</span>: <span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;year&#39;</span>: <span class="st">&#39;Year&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="231">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>density_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="231">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Year</th>
      <th>population_density</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>1950</td>
      <td>11.457986</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>1950</td>
      <td>45.714672</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Algeria</td>
      <td>1950</td>
      <td>3.787091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>American Samoa</td>
      <td>1950</td>
      <td>95.160000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Andorra</td>
      <td>1950</td>
      <td>12.776596</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>GDP per capita data</p>
</div>
<div class="cell markdown">
<p>The GDP per capita data is already in a proper format for merging the
tables, so all that needs to be done is filtering the table to only have
rows from the years 2001-2017, dropping any unnecessary columns, and
renaming the 'year' column.</p>
</div>
<div class="cell code" data-execution_count="232">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years not used in the study (only 2001-2017)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data[(gdp_data[<span class="st">&#39;year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2001</span>) <span class="op">&amp;</span> (gdp_data[<span class="st">&#39;year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>, <span class="st">&#39;GDP_USD&#39;</span>])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># renaming &#39;year to &#39;Year&#39;</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data.rename(columns<span class="op">=</span>{<span class="st">&#39;year&#39;</span>: <span class="st">&#39;Year&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="233">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>gdp_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="233">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Year</th>
      <th>GDP_per_capita_USD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10906</th>
      <td>Aruba</td>
      <td>2001</td>
      <td>20417.775960</td>
    </tr>
    <tr>
      <th>10907</th>
      <td>Africa Eastern and Southern</td>
      <td>2001</td>
      <td>633.548479</td>
    </tr>
    <tr>
      <th>10908</th>
      <td>Afghanistan</td>
      <td>2001</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10909</th>
      <td>Africa Western and Central</td>
      <td>2001</td>
      <td>539.338735</td>
    </tr>
    <tr>
      <th>10910</th>
      <td>Angola</td>
      <td>2001</td>
      <td>527.333529</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Unemployment data</p>
<p>Similar to the population data, the unemployment data is formatted
with columns for country name, country code, and a column for each year
in the table (1991-2021) with values for the percentage of the
population in that country that was unemployed. This dataframe will be
melted as well, so that the resulting columns in the dataframe are
country name, country code, year, and unemployment %.</p>
</div>
<div class="cell code" data-execution_count="234">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># melting the unemployment data to reshape it </span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data.melt(id_vars<span class="op">=</span>[<span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;Country Code&#39;</span>], var_name<span class="op">=</span><span class="st">&#39;Year&#39;</span>, value_name<span class="op">=</span><span class="st">&#39;Unemployment (%)&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Next, the 'year' column will need to be typecasted as an int, and the
rows will be filtered so that only years from 2001-2017 are in the
table. Furthermore, irrelevant columns from the table are dropped.</p>
</div>
<div class="cell code" data-execution_count="235">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># typecasting year to int </span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">=</span> unemployment_data[<span class="st">&#39;Year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years not used in the study (only 2001-2017)</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data[(unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2001</span>) <span class="op">&amp;</span> (unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="236">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>unemployment_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="236">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Year</th>
      <th>Unemployment (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2350</th>
      <td>Africa Eastern and Southern</td>
      <td>2001</td>
      <td>7.73</td>
    </tr>
    <tr>
      <th>2351</th>
      <td>Afghanistan</td>
      <td>2001</td>
      <td>10.81</td>
    </tr>
    <tr>
      <th>2352</th>
      <td>Africa Western and Central</td>
      <td>2001</td>
      <td>4.87</td>
    </tr>
    <tr>
      <th>2353</th>
      <td>Angola</td>
      <td>2001</td>
      <td>4.00</td>
    </tr>
    <tr>
      <th>2354</th>
      <td>Albania</td>
      <td>2001</td>
      <td>18.58</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Healthcare expenditure and life expectancy data</p>
</div>
<div class="cell markdown">
<p>The healthcare expenditure data is properly formatted, but needs to
be filtered to contain years from 2001-2017 and unecessary columns from
the table are dropped.</p>
</div>
<div class="cell code" data-execution_count="237">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years not used in the study (only 2001-2017)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> expenditure_data[(expenditure_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2001</span>) <span class="op">&amp;</span> (expenditure_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study </span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> expenditure_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>, <span class="st">&#39;Prevelance of Undernourishment&#39;</span>, <span class="st">&#39;CO2&#39;</span>, <span class="st">&#39;Education Expenditure %&#39;</span>, <span class="st">&#39;Corruption&#39;</span>, <span class="st">&#39;Sanitation&#39;</span>, <span class="st">&#39;Injuries&#39;</span>, <span class="st">&#39;Communicable&#39;</span>, <span class="st">&#39;NonCommunicable&#39;</span>, <span class="st">&#39;Unemployment&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="238">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>expenditure_data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="238">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Region</th>
      <th>IncomeGroup</th>
      <th>Year</th>
      <th>Life Expectancy World Bank</th>
      <th>Health Expenditure %</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>2001</td>
      <td>56.308</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Angola</td>
      <td>Sub-Saharan Africa</td>
      <td>Lower middle income</td>
      <td>2001</td>
      <td>47.059</td>
      <td>4.483516</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Albania</td>
      <td>Europe &amp; Central Asia</td>
      <td>Upper middle income</td>
      <td>2001</td>
      <td>74.288</td>
      <td>7.139524</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Andorra</td>
      <td>Europe &amp; Central Asia</td>
      <td>High income</td>
      <td>2001</td>
      <td>NaN</td>
      <td>5.865939</td>
    </tr>
    <tr>
      <th>4</th>
      <td>United Arab Emirates</td>
      <td>Middle East &amp; North Africa</td>
      <td>High income</td>
      <td>2001</td>
      <td>74.544</td>
      <td>2.484370</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p><strong>Merging the Data</strong></p>
<p>Now that the data has all been properly formatted, these datasets
will be merged together. There are 5 dataframes that will be merged, and
each contain the following data from each year during the 2001-2017 time
period:</p>
<ul>
<li><strong>mental_health_data</strong>: contains all mental health
disorder data for each country</li>
<li><strong>density_data</strong>: contains the population density for
each country</li>
<li><strong>gdp_data</strong>: contains the GDP per capita in USD for
each country</li>
<li><strong>unemployment_data</strong>: contains the percentage of the
population in each country that was unemployed</li>
<li><strong>expenditure_data</strong>: contains data on the life
expectancy and health expenditure % for each country</li>
</ul>
<p>These dataframes will be merged using the reduce function in Python
along with the Panda's merge function, which continuously merges each
dataframe on a left merge, starting with the main dataframe, the mental
health data.</p>
</div>
<div class="cell code" data-execution_count="239">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list of all dataframes used for merging </span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> [mental_health_data, density_data, gdp_data, unemployment_data, expenditure_data]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># using reduce function to merge the dataframes </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> <span class="bu">reduce</span>(<span class="kw">lambda</span> left_df, right_df: pd.merge(left_df, right_df, on<span class="op">=</span>[<span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;Year&#39;</span>], how<span class="op">=</span><span class="st">&#39;left&#39;</span>), frames)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">&#39;Country Name&#39;</span>: <span class="st">&#39;country_name&#39;</span>, <span class="st">&#39;Year&#39;</span>: <span class="st">&#39;year&#39;</span>, <span class="st">&#39;Schizophrenia (%)&#39;</span>: <span class="st">&#39;schizophrenia&#39;</span>, <span class="st">&#39;Bipolar disorder (%)&#39;</span>: <span class="st">&#39;bipolar_disorder&#39;</span>, <span class="st">&#39;Eating disorders (%)&#39;</span>: <span class="st">&#39;eating_disorders&#39;</span>, <span class="st">&#39;Anxiety disorders (%)&#39;</span>: <span class="st">&#39;anxiety_disorders&#39;</span>, <span class="st">&#39;Drug use disorders (%)&#39;</span>: <span class="st">&#39;drug_use_disorders&#39;</span>, <span class="st">&#39;Depression (%)&#39;</span>: <span class="st">&#39;depression&#39;</span>, <span class="st">&#39;Alcohol use disorders (%)&#39;</span>: <span class="st">&#39;alcohol_use_disorders&#39;</span>, <span class="st">&#39;Unemployment (%)&#39;</span>: <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;Region&#39;</span>: <span class="st">&#39;region&#39;</span>, <span class="st">&#39;IncomeGroup&#39;</span>: <span class="st">&#39;income_group&#39;</span>, <span class="st">&#39;Life Expectancy World Bank&#39;</span>: <span class="st">&#39;life_expectancy&#39;</span>, <span class="st">&#39;Health Expenditure %&#39;</span>: <span class="st">&#39;health_expenditure_%&#39;</span>})</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="239">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_name</th>
      <th>year</th>
      <th>schizophrenia</th>
      <th>bipolar_disorder</th>
      <th>eating_disorders</th>
      <th>anxiety_disorders</th>
      <th>drug_use_disorders</th>
      <th>depression</th>
      <th>alcohol_use_disorders</th>
      <th>population_density</th>
      <th>GDP_per_capita_USD</th>
      <th>unemployment_%</th>
      <th>region</th>
      <th>income_group</th>
      <th>life_expectancy</th>
      <th>health_expenditure_%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>2001</td>
      <td>0.161957</td>
      <td>0.700499</td>
      <td>0.086517</td>
      <td>4.831409</td>
      <td>1.839123</td>
      <td>4.121381</td>
      <td>0.661158</td>
      <td>30.157510</td>
      <td>NaN</td>
      <td>10.81</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>56.308</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Afghanistan</td>
      <td>2002</td>
      <td>0.162414</td>
      <td>0.701141</td>
      <td>0.087023</td>
      <td>4.838318</td>
      <td>1.934326</td>
      <td>4.124928</td>
      <td>0.659213</td>
      <td>32.166553</td>
      <td>179.426579</td>
      <td>11.26</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>56.784</td>
      <td>9.443390</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Afghanistan</td>
      <td>2003</td>
      <td>0.162916</td>
      <td>0.701860</td>
      <td>0.087189</td>
      <td>4.845538</td>
      <td>2.051106</td>
      <td>4.125230</td>
      <td>0.657354</td>
      <td>34.686043</td>
      <td>190.683814</td>
      <td>11.14</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>57.271</td>
      <td>8.941258</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Afghanistan</td>
      <td>2004</td>
      <td>0.163377</td>
      <td>0.702556</td>
      <td>0.088158</td>
      <td>4.851512</td>
      <td>2.163044</td>
      <td>4.126384</td>
      <td>0.656132</td>
      <td>36.077491</td>
      <td>211.382074</td>
      <td>10.99</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>57.772</td>
      <td>9.808474</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Afghanistan</td>
      <td>2005</td>
      <td>0.163706</td>
      <td>0.703078</td>
      <td>0.088933</td>
      <td>4.854684</td>
      <td>2.247443</td>
      <td>4.126908</td>
      <td>0.655686</td>
      <td>37.391157</td>
      <td>242.031313</td>
      <td>11.22</td>
      <td>South Asia</td>
      <td>Low income</td>
      <td>58.290</td>
      <td>9.948290</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p><strong>Cleaning the Merged Data</strong></p>
</div>
<div class="cell markdown">
<p>From some analysis (not shown here) showing all the unique country
names present in the dataframe, there seems to have been many entries
from the mental health data where country names were broad regions
throughout the world, such as 'Central Asia', 'North America', etc.
Since this study is on the country level, and not region level, all rows
with country names similar to these will be dropped from the table.</p>
</div>
<div class="cell code" data-execution_count="240">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>names_drop <span class="op">=</span> [<span class="st">&#39;Australasia&#39;</span>, <span class="st">&#39;Central Asia&#39;</span>, <span class="st">&#39;Central Europe&#39;</span>, <span class="st">&#39;Central Europe, Eastern Europe, and Central Asia&#39;</span>, </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;Central Latin America&#39;</span>, <span class="st">&#39;Central Sub-Saharan Africa&#39;</span>, <span class="st">&#39;Eastern Europe&#39;</span>, <span class="st">&#39;East Asia&#39;</span>, </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;Eastern Sub-Saharan Africa&#39;</span>, <span class="st">&#39;High SDI&#39;</span>, <span class="st">&#39;High-income&#39;</span>, <span class="st">&#39;High-income Asia Pacific&#39;</span>, </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;High-middle SDI&#39;</span>, <span class="st">&#39;Latin America and Caribbean&#39;</span>, <span class="st">&#39;Low SDI&#39;</span>, <span class="st">&#39;Low-middle SDI&#39;</span>, <span class="st">&#39;Middle SDI&#39;</span>, </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;Micronesia (country)&#39;</span>, <span class="st">&#39;North Africa and Middle East&#39;</span>, <span class="st">&#39;North America&#39;</span>, <span class="st">&#39;Oceania&#39;</span>, </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;Southeast Asia&#39;</span>, <span class="st">&#39;Southeast Asia, East Asia, and Oceania&#39;</span>, <span class="st">&#39;Southern Latin America&#39;</span>, </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;Southern Sub-Saharan Africa&#39;</span>, <span class="st">&#39;South Asia&#39;</span>, <span class="st">&#39;Sub-Saharan Africa&#39;</span>, <span class="st">&#39;Tropical Latin America&#39;</span>,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;United States Virgin Islands&#39;</span>, <span class="st">&#39;Western Europe&#39;</span>, <span class="st">&#39;Western Sub-Saharan Africa&#39;</span>, <span class="st">&#39;World&#39;</span>]</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[<span class="op">~</span>df[<span class="st">&#39;country_name&#39;</span>].isin(names_drop)]</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Furthermore, we also want to make sure we remove any countries from
the DataFrame that did not have corresponding data from the other tables
during the merge. There were 7 new columns that were merged onto the
mental health data (population density, GDP per capita in USD,
unemployment %, region, income group, life expectancy, and healthcare
expenditure %). For this study, we will assume that if there are at
least 2 of these columns that contain all NaN values for a country
(during every year from 2001-2017), there is not sufficient data for the
particular country and the country should be excluded from the study.
The following gets the countries and how many years in the study these
countries are missing at least 2 columns of data. Most countries part of
this filtering had 17 years of missing data, which is the entire study
period.</p>
</div>
<div class="cell code" data-execution_count="241">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># showing the countries and how many rows for the country did not meet the data criteria </span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>filtered <span class="op">=</span> df[df.isna().<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&gt;=</span> <span class="dv">2</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> filtered.groupby(<span class="st">&#39;country_name&#39;</span>).size()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>These countries will be dropped from the DataFrame as there is not
sufficient data to include them for the analysis.</p>
</div>
<div class="cell code" data-execution_count="242">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the names of these countries to drop</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>names_drop <span class="op">=</span> counts[counts <span class="op">&gt;=</span> <span class="dv">16</span>].index.tolist()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping all countries from the table where at least two columns are NaN for at least 16 years of the study </span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>df_cleaned <span class="op">=</span> df[<span class="op">~</span>df[<span class="st">&#39;country_name&#39;</span>].isin(names_drop)]</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df_cleaned</span></code></pre></div>
</div>
<div class="cell markdown">
<p><strong>Fixing Missing Data</strong></p>
</div>
<div class="cell markdown">
<p>Now that any insufficient countries for the analysis have been
removed from the DataFrame, we will see how much more missing data
remains in the table. The following shows the proportion of rows in the
table that contain at least one NaN value.</p>
</div>
<div class="cell code" data-execution_count="243">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Number of rows containing an NaN value: &quot;</span>, <span class="bu">len</span>(df[df.isna().<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Proportion of NaN rows in the entire DataFrame: &quot;</span>, <span class="bu">len</span>(df[df.isna().<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>)]) <span class="op">/</span> <span class="bu">len</span>(df))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of rows containing an NaN value:  204
Proportion of NaN rows in the entire DataFrame:  0.075
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Although this proportion is very small, there should be no missing
values present in the table during further analysis. Below shows the
proportion of missing values in the table for each column, as some
columns may have more missing data than others. This will allow us to
determine how to proceed with filling in missing data values.</p>
</div>
<div class="cell code" data-execution_count="244">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>nans <span class="op">=</span> df.isna().mean() </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>nans</span></code></pre></div>
<div class="output execute_result" data-execution_count="244">
<pre><code>country_name             0.000000
year                     0.000000
schizophrenia            0.000000
bipolar_disorder         0.000000
eating_disorders         0.000000
anxiety_disorders        0.000000
drug_use_disorders       0.000000
depression               0.000000
alcohol_use_disorders    0.000000
population_density       0.012500
GDP_per_capita_USD       0.010662
unemployment_%           0.025000
region                   0.000000
income_group             0.000000
life_expectancy          0.000000
health_expenditure_%     0.034926
dtype: float64</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The original dataframe before filling in the missing values through
imputation will be saved as a separate dataframe. This is so that
potential bias introduced during imputation can be analyzed after all
missing data is filled in.</p>
</div>
<div class="cell code" data-execution_count="245">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>original_df <span class="op">=</span> df</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Population density missing data</p>
</div>
<div class="cell markdown">
<p>Below shows that the two countries without population density data
for the study period are Cote d'Ivoire and Sao Tome and Principe.
Neither of these countries have population desnity data for the entire
study period (2001-2017).</p>
</div>
<div class="cell code" data-execution_count="246">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>pop <span class="op">=</span> df[<span class="st">&#39;population_density&#39;</span>].isna()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>countries <span class="op">=</span> df[pop]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>countries[<span class="st">&#39;country_name&#39;</span>].unique()</span></code></pre></div>
<div class="output execute_result" data-execution_count="246">
<pre><code>array([&quot;Cote d&#39;Ivoire&quot;, &#39;Sao Tome and Principe&#39;], dtype=object)</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Upon further investigation, the original dataset had the necessary
data to calculate the population density for these two countries, but
their spellings in this dataset were slightly different than the
spellings of the countries in other datasets, which is why they are
missing the data from this. The land area is shown in the original
dataset for Cote d'Ivoire (318,000 km^2) and Sao Tome and Principe (960
km^2). To fix the missing values, the original yearly population data
will used to calculate the population density for these two countries,
and then used to fill in the missing values in the current
dataframe.</p>
</div>
<div class="cell code" data-execution_count="247">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting Cote d&#39;Ivoire and Sao Tome and Principe&#39;s population density data</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>countries <span class="op">=</span> [<span class="st">&#39;Côte d</span><span class="ch">\&#39;</span><span class="st">Ivoire&#39;</span>, <span class="st">&#39;Sao Tome &amp; Principe&#39;</span>]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>filtered_countries <span class="op">=</span> density_data[density_data[<span class="st">&#39;Country Name&#39;</span>].isin(countries) <span class="op">&amp;</span> density_data[<span class="st">&#39;Year&#39;</span>].between(<span class="dv">2001</span>,<span class="dv">2017</span>)]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="248">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filling in missing population_density values in df for Côte d&#39;Ivoire and Sao Tome &amp; Principe</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, r <span class="kw">in</span> filtered_countries.iterrows():</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># country is Côte d&#39;Ivoire, update its corresponding row in dataframe </span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> r[<span class="st">&#39;Country Name&#39;</span>] <span class="op">==</span> <span class="st">&#39;Côte d</span><span class="ch">\&#39;</span><span class="st">Ivoire&#39;</span>:</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>        cond <span class="op">=</span> (df[<span class="st">&#39;country_name&#39;</span>] <span class="op">==</span> <span class="st">&#39;Cote d</span><span class="ch">\&#39;</span><span class="st">Ivoire&#39;</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;year&#39;</span>] <span class="op">==</span> r[<span class="st">&#39;Year&#39;</span>])</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>        df.loc[cond, <span class="st">&#39;population_density&#39;</span>] <span class="op">=</span> r[<span class="st">&#39;population_density&#39;</span>]</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># country is Sao Tome &amp; Principe, update its corresponding row in dataframe </span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>        cond <span class="op">=</span> (df[<span class="st">&#39;country_name&#39;</span>] <span class="op">==</span> <span class="st">&#39;Sao Tome and Principe&#39;</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;year&#39;</span>] <span class="op">==</span> r[<span class="st">&#39;Year&#39;</span>])</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>        df.loc[cond, <span class="st">&#39;population_density&#39;</span>] <span class="op">=</span> r[<span class="st">&#39;population_density&#39;</span>]</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Healthcare expenditure % missing data</p>
</div>
<div class="cell markdown">
<p>Since there is not much missing data for healthcare expenditure % and
most of the other missing data in the table has been filled in, linear
regression will be used to fill in the data for the missing years.</p>
</div>
<div class="cell code" data-execution_count="249">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># performing linear regression to fill in the missing values under healthcare expenditure % based </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># on year, population density, and life expectancy. </span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the training data </span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>training_data <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&#39;health_expenditure_%&#39;</span>])</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>X_training <span class="op">=</span> training_data[[<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;life_expectancy&#39;</span>]]</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>y_training <span class="op">=</span> training_data[<span class="st">&#39;health_expenditure_%&#39;</span>]</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the linear regression model for predicting healthcare expenditure %</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>model.fit(X_training, y_training)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># getting indices in the dataframe where healthcare expenditure % is NaN </span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>missing_indices <span class="op">=</span> df[df[<span class="st">&#39;health_expenditure_%&#39;</span>].isna()].index</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting value for NaN rows </span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>missing_row <span class="op">=</span> df.loc[missing_indices, [<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;life_expectancy&#39;</span>]]</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(missing_row)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co"># filling in NaN values with predictions </span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>df.loc[missing_indices, <span class="st">&#39;health_expenditure_%&#39;</span>] <span class="op">=</span> predictions</span></code></pre></div>
</div>
<div class="cell markdown">
<p>GDP per capita missing data</p>
</div>
<div class="cell markdown">
<p>The rows in the table with missing values in the GDP per capita
column are more scattered, as there are not any countries in the table
with missing GDP values throughout the whole study period. Here, we can
use a linear regression model to predict the GDP per capita in USD for
these rows with missing data.</p>
</div>
<div class="cell code" data-execution_count="250">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># performing linear regression to fill in the missing values under unemployment % based </span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># on year, population density, and healthcare expenditure %</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the training data </span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>training_data <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&#39;GDP_per_capita_USD&#39;</span>])</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>X_training <span class="op">=</span> training_data[[<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>y_training <span class="op">=</span> training_data[<span class="st">&#39;GDP_per_capita_USD&#39;</span>]</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the linear regression model for predicting healthcare expenditure %</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>model.fit(X_training, y_training)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co"># getting indices in the dataframe where healthcare expenditure % is NaN </span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>missing_indices <span class="op">=</span> df[df[<span class="st">&#39;GDP_per_capita_USD&#39;</span>].isna()].index</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting value for NaN rows </span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>missing_row <span class="op">=</span> df.loc[missing_indices, [<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(missing_row)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># filling in NaN values with predictions </span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>df.loc[missing_indices, <span class="st">&#39;GDP_per_capita_USD&#39;</span>] <span class="op">=</span> predictions</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Unemployment % missing data</p>
</div>
<div class="cell markdown">
<p>Countries with missing unemployment % data are also scattered, so
these missing years will be filled in using linear regression with the
following predictors: year, population density, healthcare expenditure
%, GDP per capita.</p>
</div>
<div class="cell code" data-execution_count="251">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># performing linear regression to fill in the missing values under unemployment % based </span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># on year, population density, and healthcare expenditure %, and GDP per capita</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the training data </span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>training_data <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&#39;unemployment_%&#39;</span>])</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>X_training <span class="op">=</span> training_data[[<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>]]</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>y_training <span class="op">=</span> training_data[<span class="st">&#39;unemployment_%&#39;</span>]</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the linear regression model for predicting healthcare expenditure %</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>model.fit(X_training, y_training)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co"># getting indices in the dataframe where healthcare expenditure % is NaN </span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>missing_indices <span class="op">=</span> df[df[<span class="st">&#39;unemployment_%&#39;</span>].isna()].index</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting value for NaN rows </span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>missing_row <span class="op">=</span> df.loc[missing_indices, [<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>]]</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(missing_row)</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="co"># filling in NaN values with predictions </span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>df.loc[missing_indices, <span class="st">&#39;unemployment_%&#39;</span>] <span class="op">=</span> predictions</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Now all of the missing data has been filled! We can verify this with
the same code as above, which calculates the proportions of each column
that have NaN values present in the table.</p>
</div>
<div class="cell code" data-execution_count="252">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>nans <span class="op">=</span> df.isna().mean() </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>nans</span></code></pre></div>
<div class="output execute_result" data-execution_count="252">
<pre><code>country_name             0.0
year                     0.0
schizophrenia            0.0
bipolar_disorder         0.0
eating_disorders         0.0
anxiety_disorders        0.0
drug_use_disorders       0.0
depression               0.0
alcohol_use_disorders    0.0
population_density       0.0
GDP_per_capita_USD       0.0
unemployment_%           0.0
region                   0.0
income_group             0.0
life_expectancy          0.0
health_expenditure_%     0.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Part 3: Exploratory Data Analysis and Data
Visualization</strong></p>
</div>
<div class="cell markdown">
<p><strong>Analyzing Pre and Post Imputation</strong></p>
</div>
<div class="cell markdown">
<p>As a result of imputing some of the missing data, some bias could
have been introduced. In order to understand if any bias introduced
would have a significant effect on later analysis, the standard
deviation and mean for each of the predictor variables that were imputed
in the study will be plotted using the following function.</p>
</div>
<div class="cell code" data-execution_count="253">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_imputation_effects(feature, feature_name, ylabel):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># computing the mean and standard deviation for the original dataframe </span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    original_means <span class="op">=</span> original_df.groupby(<span class="st">&#39;year&#39;</span>)[feature].mean()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    original_std <span class="op">=</span> original_df.groupby(<span class="st">&#39;year&#39;</span>)[feature].std()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># computing the mean and standard deviation for the post-imputation dataframe </span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    post_imp_means <span class="op">=</span> df.groupby(<span class="st">&#39;year&#39;</span>)[feature].mean()</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    post_imp_std <span class="op">=</span> df.groupby(<span class="st">&#39;year&#39;</span>)[feature].std()</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot for standard deviations </span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    plt.plot(original_std.index, original_std.values, label<span class="op">=</span><span class="st">&#39;Pre-imputation&#39;</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    plt.plot(post_imp_std.index, post_imp_std.values, label<span class="op">=</span><span class="st">&#39;Post-imputation&#39;</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Year&#39;</span>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(ylabel)</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Standard deviations of </span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss"> by year&#39;</span>)</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot for means </span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    plt.plot(original_means.index, original_means.values, label<span class="op">=</span><span class="st">&#39;Pre-imputation&#39;</span>)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    plt.plot(post_imp_means.index, post_imp_means.values, label<span class="op">=</span><span class="st">&#39;Post-imputation&#39;</span>)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Year&#39;</span>)</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(ylabel)</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Mean </span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss"> by year&#39;</span>)</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</div>
<div class="cell code" data-execution_count="254">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>plot_imputation_effects(<span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;population density&#39;</span>, <span class="st">&#39;Population density (people per km^2)&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_a650252133a84285936ab47ae295ae1c/d402fc7c6031245ae89ca751fb1460305b6ad6b9.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="255">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plot_imputation_effects(<span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;GDP per capita&#39;</span>, <span class="st">&#39;GDP per capita in USD&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_a650252133a84285936ab47ae295ae1c/eb436ed724b0cc366abdf74e781b148dfb3064b0.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="256">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>plot_imputation_effects(<span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;unemployment %&#39;</span>, <span class="st">&#39;Percent of population unemployed&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_a650252133a84285936ab47ae295ae1c/74391aeeb2e87ee571c7a26c2d6a678ec9323d12.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="257">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plot_imputation_effects(<span class="st">&#39;health_expenditure_%&#39;</span>, <span class="st">&#39;health expenditure %&#39;</span>, <span class="st">&#39;Health expenditure %&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_a650252133a84285936ab47ae295ae1c/9c49b9fca55bd263e22b933d9257640ef574e2bf.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>Great! So the filling of missing data (imputation) done in this study
did not introduce any bias into the data.</p>
</div>
<div class="cell markdown">
<p>Let's also plot the mean for each kind of mental health disorder that
is present in the data, grouped by the region the country is located
within. This will give a good showing of how the data is distributed
throughout the different countries present in the dataset.</p>
</div>
<div class="cell code" data-execution_count="258">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list of mental health disorders</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>disorders <span class="op">=</span> [<span class="st">&#39;schizophrenia&#39;</span>, <span class="st">&#39;bipolar_disorder&#39;</span>, <span class="st">&#39;eating_disorders&#39;</span>, <span class="st">&#39;anxiety_disorders&#39;</span>, <span class="st">&#39;drug_use_disorders&#39;</span>, <span class="st">&#39;depression&#39;</span>, <span class="st">&#39;alcohol_use_disorders&#39;</span>]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>disorder_names <span class="op">=</span> [<span class="st">&#39;schizophrenia&#39;</span>, <span class="st">&#39;bipolar disorder&#39;</span>, <span class="st">&#39;eating disorders&#39;</span>, <span class="st">&#39;anxiety disorders&#39;</span>, <span class="st">&#39;drug use disorders&#39;</span>, <span class="st">&#39;depression&#39;</span>, <span class="st">&#39;alcohol use disorders&#39;</span>]</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="bu">len</span>(disorders), ncols<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">30</span>))</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>fig.tight_layout(pad<span class="op">=</span><span class="fl">15.0</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, disorder <span class="kw">in</span> <span class="bu">enumerate</span>(disorders):</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># mean for mental health disorder for each income group </span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    data_to_plot <span class="op">=</span> df.groupby(<span class="st">&#39;region&#39;</span>)[disorder].mean()</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># bar plot for each region</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    data_to_plot.plot(kind<span class="op">=</span><span class="st">&#39;bar&#39;</span>, ax<span class="op">=</span>axes[i])</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f&#39;Mean prevalence of </span><span class="sc">{</span>disorder_names[i]<span class="sc">}</span><span class="ss"> by region&#39;</span>)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">&#39;Region&#39;</span>)</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="ss">f&#39;Mean prevalence of </span><span class="sc">{</span>disorder_names[i]<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_a650252133a84285936ab47ae295ae1c/33af883ac869101532f683d2feccbb775d84e936.png" /></p>
</div>
</div>
<div class="cell markdown">
<p><strong>Part 4: Analysis, Hypothesis Testing, &amp; ML</strong></p>
</div>
<div class="cell markdown">
<p><strong>Addressing Multicollinearity</strong></p>
</div>
<div class="cell markdown">
<p>Before creating any linear regression models, the presence of
multicollinearity within the independent variables should be checked.
Multicollinearity is when at least two independent variables in a study
are highly correlated with each other, which can lead to issues when
trying to examine the significance of individual variables in the
model.</p>
<p>In order to detect potentially harmful multicollinearity, the
Variance Inflation Factor (VIF) will be employed. The VIF measures how
significantly the variance of the regression coefficient increases due
to multicollinearity. If the VIF is 1, variables are not correlated. If
the VIF is between 1 and 5, the variables are moderately correlated, and
if the VIF is larger than 5, the variables are highly correlated and one
should be removed or alternative approaches for their correlation should
be explored.</p>
<p>More information regarding the VIF can be found here: <a
href="https://www.investopedia.com/terms/v/variance-inflation-factor.asp"
class="uri">https://www.investopedia.com/terms/v/variance-inflation-factor.asp</a></p>
<p>Before calculating the VIF for the independent variables, we should
view the correlation matrix for the independent variables.</p>
</div>
<div class="cell code" data-execution_count="259">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation matrix for the independent variables in the study </span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;unemployment_%&#39;</span>, </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;life_expectancy&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]].corr()</span></code></pre></div>
<div class="output execute_result" data-execution_count="259">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>population_density</th>
      <th>GDP_per_capita_USD</th>
      <th>unemployment_%</th>
      <th>life_expectancy</th>
      <th>health_expenditure_%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>population_density</th>
      <td>1.000000</td>
      <td>0.159300</td>
      <td>-0.089919</td>
      <td>0.170302</td>
      <td>-0.066740</td>
    </tr>
    <tr>
      <th>GDP_per_capita_USD</th>
      <td>0.159300</td>
      <td>1.000000</td>
      <td>-0.103030</td>
      <td>0.589776</td>
      <td>0.369825</td>
    </tr>
    <tr>
      <th>unemployment_%</th>
      <td>-0.089919</td>
      <td>-0.103030</td>
      <td>1.000000</td>
      <td>-0.022907</td>
      <td>0.191833</td>
    </tr>
    <tr>
      <th>life_expectancy</th>
      <td>0.170302</td>
      <td>0.589776</td>
      <td>-0.022907</td>
      <td>1.000000</td>
      <td>0.343019</td>
    </tr>
    <tr>
      <th>health_expenditure_%</th>
      <td>-0.066740</td>
      <td>0.369825</td>
      <td>0.191833</td>
      <td>0.343019</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>From this, we can see that life expectancy and GDP per capita are
somewhat highly correlated. Let's now analyze the VIF values betweeen
the features in the study, and decide if any VIF are strong enough to
take further action.</p>
</div>
<div class="cell code" data-execution_count="260">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculating the VIF between features in the table </span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;life_expectancy&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>vif <span class="op">=</span> pd.DataFrame()</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>vif[<span class="st">&#39;Feature&#39;</span>] <span class="op">=</span> X.columns </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>vif[<span class="st">&#39;VIF&#39;</span>] <span class="op">=</span> [variance_inflation_factor(X.values, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>vif</span></code></pre></div>
<div class="output execute_result" data-execution_count="260">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>population_density</td>
      <td>1.163772</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GDP_per_capita_USD</td>
      <td>1.827030</td>
    </tr>
    <tr>
      <th>2</th>
      <td>unemployment_%</td>
      <td>2.944398</td>
    </tr>
    <tr>
      <th>3</th>
      <td>life_expectancy</td>
      <td>9.151506</td>
    </tr>
    <tr>
      <th>4</th>
      <td>health_expenditure_%</td>
      <td>8.924534</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Life expectancy has a very high VIF value, meaning it is highly
correlated with the other features in the model (it is on the cusp of
having a severe VIF value of 10). Because of this, the life expectancy
feature will be dropped, since it may have distorting effects on the
analysis. The VIF between variables will also be recalculated, and
hopefully removing life expectancy from the features will reduce the
VIFs significantly.</p>
</div>
<div class="cell code" data-execution_count="261">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">&#39;life_expectancy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="262">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculating the VIF between life expectancy and GDP per capita </span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>vif <span class="op">=</span> pd.DataFrame()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>vif[<span class="st">&#39;Feature&#39;</span>] <span class="op">=</span> X.columns </span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>vif[<span class="st">&#39;VIF&#39;</span>] <span class="op">=</span> [variance_inflation_factor(X.values, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>vif</span></code></pre></div>
<div class="output execute_result" data-execution_count="262">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>population_density</td>
      <td>1.102698</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GDP_per_capita_USD</td>
      <td>1.798486</td>
    </tr>
    <tr>
      <th>2</th>
      <td>unemployment_%</td>
      <td>2.691886</td>
    </tr>
    <tr>
      <th>3</th>
      <td>health_expenditure_%</td>
      <td>3.796498</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>From this, we can see that the VIF values between variables has
reduced significantly. We have now adjusted the data by removing high
multicollinearity, which should make it more suitable and stable for the
study. We can now move into the hypothesis testing phase of the
study.</p>
</div>
<div class="cell markdown">
<p><strong>Hypothesis Testing</strong></p>
</div>
<div class="cell markdown">
<p>The different categories of mental health data we have present in the
dataframe are:</p>
<ul>
<li>Schizophrenia</li>
<li>Bipolar disorder</li>
<li>Eating disorders</li>
<li>Anxiety disorders</li>
<li>Drug use disorders</li>
<li>Depression</li>
<li>Alcohol use disorders</li>
</ul>
<p>These are represented in the dataframe as the percentage of the
country's population that has the particular mental health disorder.</p>
<p>We will first start with creating preliminary linear regression
models to examine the relationships between the independent variables
(population density, GDP per capita, unemployment %, and healthcare
expenditure %) on each of the above mental health disorders. This will
be done by using the Ordinary Least Squares (OLS) regression for a
linear regression model. More about this can be found here: <a
href="https://www.statsmodels.org/devel/example_formulas.html"
class="uri">https://www.statsmodels.org/devel/example_formulas.html</a></p>
</div>
<div class="cell markdown">
<p>Schizophrenia model</p>
</div>
<div class="cell code" data-execution_count="263">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>reg_schizophrenia <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;schizophrenia ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>reg_schizophrenia.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="263">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>      <td>schizophrenia</td>  <th>  R-squared:         </th>  <td>   0.417</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.416</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   388.1</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 14 May 2024</td> <th>  Prob (F-statistic):</th>  <td>1.25e-314</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:34:25</td>     <th>  Log-Likelihood:    </th>  <td>  5408.2</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  2720</td>      <th>  AIC:               </th> <td>-1.080e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  2714</td>      <th>  BIC:               </th> <td>-1.077e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    1.2934</td> <td>    0.264</td> <td>    4.906</td> <td> 0.000</td> <td>    0.776</td> <td>    1.810</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0006</td> <td>    0.000</td> <td>   -4.215</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>
</tr>
<tr>
  <th>population_density</th>        <td> 7.565e-06</td> <td>  1.1e-06</td> <td>    6.895</td> <td> 0.000</td> <td> 5.41e-06</td> <td> 9.72e-06</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> 1.332e-06</td> <td> 3.96e-08</td> <td>   33.646</td> <td> 0.000</td> <td> 1.25e-06</td> <td> 1.41e-06</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>   -0.0007</td> <td>    0.000</td> <td>   -6.147</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0024</td> <td>    0.000</td> <td>    8.438</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>517.821</td> <th>  Durbin-Watson:     </th> <td>   0.121</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1330.559</td> 
</tr>
<tr>
  <th>Skew:</th>          <td> 1.028</td>  <th>  Prob(JB):          </th> <td>1.18e-289</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 5.741</td>  <th>  Cond. No.          </th> <td>9.00e+06</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Bipolar disorder model</p>
</div>
<div class="cell code" data-execution_count="264">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>reg_bipolar_disorder <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;bipolar_disorder ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>reg_bipolar_disorder.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="264">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>bipolar_disorder</td> <th>  R-squared:         </th> <td>   0.328</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.327</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   265.2</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 14 May 2024</td> <th>  Prob (F-statistic):</th> <td>2.50e-231</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:34:25</td>     <th>  Log-Likelihood:    </th> <td>  1641.7</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  2720</td>      <th>  AIC:               </th> <td>  -3271.</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  2714</td>      <th>  BIC:               </th> <td>  -3236.</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    5.2324</td> <td>    1.053</td> <td>    4.970</td> <td> 0.000</td> <td>    3.168</td> <td>    7.297</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0023</td> <td>    0.001</td> <td>   -4.412</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>
</tr>
<tr>
  <th>population_density</th>        <td>-7.583e-06</td> <td> 4.38e-06</td> <td>   -1.731</td> <td> 0.084</td> <td>-1.62e-05</td> <td> 1.01e-06</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td>  4.34e-06</td> <td> 1.58e-07</td> <td>   27.459</td> <td> 0.000</td> <td> 4.03e-06</td> <td> 4.65e-06</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0026</td> <td>    0.000</td> <td>    5.726</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0115</td> <td>    0.001</td> <td>   10.165</td> <td> 0.000</td> <td>    0.009</td> <td>    0.014</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>41.540</td> <th>  Durbin-Watson:     </th> <td>   0.130</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  56.703</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.190</td> <th>  Prob(JB):          </th> <td>4.86e-13</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.597</td> <th>  Cond. No.          </th> <td>9.00e+06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Eating disorders model</p>
</div>
<div class="cell code" data-execution_count="265">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>reg_eating_disorders <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;eating_disorders ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>reg_eating_disorders.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="265">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>eating_disorders</td> <th>  R-squared:         </th> <td>   0.707</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.706</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1309.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 14 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>11:34:25</td>     <th>  Log-Likelihood:    </th> <td>  2720.2</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  2720</td>      <th>  AIC:               </th> <td>  -5428.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  2714</td>      <th>  BIC:               </th> <td>  -5393.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    4.2339</td> <td>    0.708</td> <td>    5.978</td> <td> 0.000</td> <td>    2.845</td> <td>    5.623</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0021</td> <td>    0.000</td> <td>   -5.865</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>
</tr>
<tr>
  <th>population_density</th>        <td> 9.889e-06</td> <td> 2.95e-06</td> <td>    3.355</td> <td> 0.001</td> <td> 4.11e-06</td> <td> 1.57e-05</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> 6.947e-06</td> <td> 1.06e-07</td> <td>   65.344</td> <td> 0.000</td> <td> 6.74e-06</td> <td> 7.16e-06</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0012</td> <td>    0.000</td> <td>    3.841</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0116</td> <td>    0.001</td> <td>   15.244</td> <td> 0.000</td> <td>    0.010</td> <td>    0.013</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>624.039</td> <th>  Durbin-Watson:     </th> <td>   0.153</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2630.003</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 1.056</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 7.330</td>  <th>  Cond. No.          </th> <td>9.00e+06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Anxiety disorders model</p>
</div>
<div class="cell code" data-execution_count="266">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>reg_anxiety_disorders <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;anxiety_disorders ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>reg_anxiety_disorders.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="266">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>anxiety_disorders</td> <th>  R-squared:         </th> <td>   0.374</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.373</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   324.9</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 14 May 2024</td>  <th>  Prob (F-statistic):</th> <td>3.01e-273</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:34:25</td>      <th>  Log-Likelihood:    </th> <td> -3666.1</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  2720</td>       <th>  AIC:               </th> <td>   7344.</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  2714</td>       <th>  BIC:               </th> <td>   7380.</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>       <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>   42.9241</td> <td>    7.410</td> <td>    5.792</td> <td> 0.000</td> <td>   28.394</td> <td>   57.454</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0199</td> <td>    0.004</td> <td>   -5.396</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.013</td>
</tr>
<tr>
  <th>population_density</th>        <td>-9.277e-05</td> <td> 3.08e-05</td> <td>   -3.008</td> <td> 0.003</td> <td>   -0.000</td> <td>-3.23e-05</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> 3.369e-05</td> <td> 1.11e-06</td> <td>   30.282</td> <td> 0.000</td> <td> 3.15e-05</td> <td> 3.59e-05</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0089</td> <td>    0.003</td> <td>    2.797</td> <td> 0.005</td> <td>    0.003</td> <td>    0.015</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0954</td> <td>    0.008</td> <td>   11.989</td> <td> 0.000</td> <td>    0.080</td> <td>    0.111</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>329.188</td> <th>  Durbin-Watson:     </th> <td>   0.137</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 511.970</td> 
</tr>
<tr>
  <th>Skew:</th>          <td> 0.857</td>  <th>  Prob(JB):          </th> <td>6.72e-112</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.256</td>  <th>  Cond. No.          </th> <td>9.00e+06</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Drug use disorders model</p>
</div>
<div class="cell code" data-execution_count="267">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>reg_drug_use_disorders <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;drug_use_disorders ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>reg_drug_use_disorders.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="267">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>drug_use_disorders</td> <th>  R-squared:         </th> <td>   0.185</td> 
</tr>
<tr>
  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.184</td> 
</tr>
<tr>
  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   123.5</td> 
</tr>
<tr>
  <th>Date:</th>              <td>Tue, 14 May 2024</td>  <th>  Prob (F-statistic):</th> <td>4.24e-118</td>
</tr>
<tr>
  <th>Time:</th>                  <td>11:34:25</td>      <th>  Log-Likelihood:    </th> <td> -1600.8</td> 
</tr>
<tr>
  <th>No. Observations:</th>       <td>  2720</td>       <th>  AIC:               </th> <td>   3214.</td> 
</tr>
<tr>
  <th>Df Residuals:</th>           <td>  2714</td>       <th>  BIC:               </th> <td>   3249.</td> 
</tr>
<tr>
  <th>Df Model:</th>               <td>     5</td>       <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    6.5782</td> <td>    3.468</td> <td>    1.897</td> <td> 0.058</td> <td>   -0.222</td> <td>   13.378</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0030</td> <td>    0.002</td> <td>   -1.727</td> <td> 0.084</td> <td>   -0.006</td> <td>    0.000</td>
</tr>
<tr>
  <th>population_density</th>        <td>-2.688e-05</td> <td> 1.44e-05</td> <td>   -1.862</td> <td> 0.063</td> <td>-5.52e-05</td> <td> 1.42e-06</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> 1.083e-05</td> <td> 5.21e-07</td> <td>   20.805</td> <td> 0.000</td> <td> 9.81e-06</td> <td> 1.19e-05</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0054</td> <td>    0.001</td> <td>    3.642</td> <td> 0.000</td> <td>    0.002</td> <td>    0.008</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0138</td> <td>    0.004</td> <td>    3.697</td> <td> 0.000</td> <td>    0.006</td> <td>    0.021</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>1116.908</td> <th>  Durbin-Watson:     </th> <td>   0.128</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4577.444</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 2.015</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 7.915</td>  <th>  Cond. No.          </th> <td>9.00e+06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Depression model</p>
</div>
<div class="cell code" data-execution_count="268">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>reg_depression <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;depression ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>reg_depression.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="268">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>depression</td>    <th>  R-squared:         </th> <td>   0.061</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.51</td>
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 14 May 2024</td> <th>  Prob (F-statistic):</th> <td>2.64e-35</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:34:25</td>     <th>  Log-Likelihood:    </th> <td> -2525.3</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  2720</td>      <th>  AIC:               </th> <td>   5063.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  2714</td>      <th>  BIC:               </th> <td>   5098.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>   21.8708</td> <td>    4.872</td> <td>    4.489</td> <td> 0.000</td> <td>   12.318</td> <td>   31.424</td>
</tr>
<tr>
  <th>year</th>                      <td>   -0.0093</td> <td>    0.002</td> <td>   -3.823</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.005</td>
</tr>
<tr>
  <th>population_density</th>        <td>-2.475e-05</td> <td> 2.03e-05</td> <td>   -1.220</td> <td> 0.222</td> <td>-6.45e-05</td> <td>  1.5e-05</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> 7.027e-06</td> <td> 7.31e-07</td> <td>    9.609</td> <td> 0.000</td> <td> 5.59e-06</td> <td> 8.46e-06</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0031</td> <td>    0.002</td> <td>    1.488</td> <td> 0.137</td> <td>   -0.001</td> <td>    0.007</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0222</td> <td>    0.005</td> <td>    4.243</td> <td> 0.000</td> <td>    0.012</td> <td>    0.032</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>166.278</td> <th>  Durbin-Watson:     </th> <td>   0.118</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 241.818</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.522</td>  <th>  Prob(JB):          </th> <td>3.09e-53</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.021</td>  <th>  Cond. No.          </th> <td>9.00e+06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p>Alcohol use disorders model</p>
</div>
<div class="cell code" data-execution_count="269">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>reg_alcohol_use_disorders <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">&#39;alcohol_use_disorders ~ year + population_density + GDP_per_capita_USD + Q(&quot;unemployment_%&quot;) + Q(&quot;health_expenditure_%&quot;)&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>reg_alcohol_use_disorders.summary()</span></code></pre></div>
<div class="output execute_result" data-execution_count="269">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>alcohol_use_disorders</td> <th>  R-squared:         </th> <td>   0.054</td>
</tr>
<tr>
  <th>Model:</th>                     <td>OLS</td>          <th>  Adj. R-squared:    </th> <td>   0.052</td>
</tr>
<tr>
  <th>Method:</th>               <td>Least Squares</td>     <th>  F-statistic:       </th> <td>   30.82</td>
</tr>
<tr>
  <th>Date:</th>               <td>Tue, 14 May 2024</td>    <th>  Prob (F-statistic):</th> <td>1.37e-30</td>
</tr>
<tr>
  <th>Time:</th>                   <td>11:34:25</td>        <th>  Log-Likelihood:    </th> <td> -3347.2</td>
</tr>
<tr>
  <th>No. Observations:</th>        <td>  2720</td>         <th>  AIC:               </th> <td>   6706.</td>
</tr>
<tr>
  <th>Df Residuals:</th>            <td>  2714</td>         <th>  BIC:               </th> <td>   6742.</td>
</tr>
<tr>
  <th>Df Model:</th>                <td>     5</td>         <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>        <td>nonrobust</td>       <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>   -2.6683</td> <td>    6.591</td> <td>   -0.405</td> <td> 0.686</td> <td>  -15.591</td> <td>   10.255</td>
</tr>
<tr>
  <th>year</th>                      <td>    0.0020</td> <td>    0.003</td> <td>    0.595</td> <td> 0.552</td> <td>   -0.004</td> <td>    0.008</td>
</tr>
<tr>
  <th>population_density</th>        <td>   -0.0002</td> <td> 2.74e-05</td> <td>   -6.595</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>
</tr>
<tr>
  <th>GDP_per_capita_USD</th>        <td> -3.79e-06</td> <td> 9.89e-07</td> <td>   -3.830</td> <td> 0.000</td> <td>-5.73e-06</td> <td>-1.85e-06</td>
</tr>
<tr>
  <th>Q("unemployment_%")</th>       <td>    0.0108</td> <td>    0.003</td> <td>    3.833</td> <td> 0.000</td> <td>    0.005</td> <td>    0.016</td>
</tr>
<tr>
  <th>Q("health_expenditure_%")</th> <td>    0.0497</td> <td>    0.007</td> <td>    7.027</td> <td> 0.000</td> <td>    0.036</td> <td>    0.064</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>1186.778</td> <th>  Durbin-Watson:     </th> <td>   0.122</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6014.755</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 2.061</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>       <td> 9.007</td>  <th>  Cond. No.          </th> <td>9.00e+06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  9e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>
</div>
<div class="cell markdown">
<p><strong>Analysis of Linear Regression Models</strong></p>
<p>From the above, it seems that the linear regression model using OLS
is only plausible for predicting eating disorders. Its R-squared of .707
indicates that approximately 70.7% of the variability for eating
disorders can be explained by the independent variables in the model,
which is a relatively high value. Furthermore, the probability of the
F-statistic (p-value) being 0.00 strongly suggests the model is
statistically significant, meaning we can reject the null hypothesis of
the predictor variables having no effect on 'eating_disorders'.</p>
<p>However, even though the model fit the eating disorders data well, it
is evident that using linear regression for the other mental health
disorder variables does not fit the data well (such as depression and
alcohol use disorder, with R-squared values being .061 and .054).
Therefore, we'll need to use another kind of model to fit the data for a
more accurate analysis.</p>
</div>
<div class="cell markdown">
<p><strong>Ridge Regression</strong></p>
</div>
<div class="cell markdown">
<p>Ridge regression is a form of regularized linear regression that adds
a penalty term to the loss function used in the OLS for linear
regression. This penalty term shrinks the coefficients, which allows for
the model to become more stable. The linear regression model may have
overfit the data in some cases, which is something that a ridge
regression model handles well through the use of the penalty term.
Furthermore, ridge regression is a more complex model, so although it
may introduce a small bias through regularization, it reduces the
variance of the coefficient estimates. This ultimately makes the model
more robust and leads to better generalization performance on new data
it wasn't trained on. More information regarding ridge regression in the
scikit-learn library can be found below:</p>
<p><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html</a></p>
</div>
<div class="cell markdown">
<p>The following function takes in a dependent variable of the study (a
type of mental health disorder from the dataframe) and uses Ridge
Regression in order to calculate the mean squared error and coefficients
for the independent variables of the study.</p>
</div>
<div class="cell code" data-execution_count="270">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ridge_regression(target):</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># getting the data</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> df[[<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> df[target]</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># scaling the data for ridge regression</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># creating the test and training sets</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_scaled, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fitting a ridge regression model on the training sets </span></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    ridge_model <span class="op">=</span> Ridge(alpha<span class="op">=</span><span class="fl">.01</span>)</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    ridge_model.fit(X_train, y_train)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predicting mental health prevalence based on the trained model</span></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> ridge_model.predict(X_test)</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculating the mean squared error for the model</span></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean Squared Error:&quot;</span>, mse)</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Coefficients:&quot;</span>)</span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot; Year: &quot;</span>, ridge_model.coef_[<span class="dv">0</span>])</span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot; Population density: &quot;</span>, ridge_model.coef_[<span class="dv">1</span>])</span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot; GDP per capita in USD: &quot;</span>, ridge_model.coef_[<span class="dv">2</span>])</span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot; Unemployment %: &quot;</span>, ridge_model.coef_[<span class="dv">3</span>])</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot; Healthcare expenditure %: &quot;</span>, ridge_model.coef_[<span class="dv">4</span>])</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ridge_model, scaler</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="271">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>schizophrenia_model, schizophrenia_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;schizophrenia&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.0010422897756428948
Coefficients:
 Year:  -0.0030064319969380434
 Population density:  0.004511853278878033
 GDP per capita in USD:  0.023989533966591158
 Unemployment %:  -0.004244926356324339
 Healthcare expenditure %:  0.006381598304819168
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="272">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>bipolar_disorder_model, bipolar_disorder_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;bipolar_disorder&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.018479390930803165
Coefficients:
 Year:  -0.010680826851078976
 Population density:  -0.004534043062132054
 GDP per capita in USD:  0.07669710270272277
 Unemployment %:  0.013800378058848081
 Healthcare expenditure %:  0.032237043835803496
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="273">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>eating_disorders_model, eating_disorders_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;eating_disorders&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.007310164245024522
Coefficients:
 Year:  -0.009793017922395597
 Population density:  0.004780124339737893
 GDP per capita in USD:  0.12425584141148217
 Unemployment %:  0.00676525964406662
 Healthcare expenditure %:  0.03190985830496571
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="274">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>anxiety_disorders_model, anxiety_disorders_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;anxiety_disorders&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.8215306561598039
Coefficients:
 Year:  -0.09805659738832509
 Population density:  -0.04945469166824152
 GDP per capita in USD:  0.5877961350144162
 Unemployment %:  0.04644111889955103
 Healthcare expenditure %:  0.24877903654753977
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="275">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>drug_use_disorders_model, drug_use_disorders_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;drug_use_disorders&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.2242524163538556
Coefficients:
 Year:  -0.016618632231454347
 Population density:  -0.017996906453284545
 GDP per capita in USD:  0.19742173776043326
 Unemployment %:  0.028087572504719896
 Healthcare expenditure %:  0.028205120534734635
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="276">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>depression_model, depression_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;depression&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.4368816737248956
Coefficients:
 Year:  -0.037673773067443225
 Population density:  -0.01773391839130413
 GDP per capita in USD:  0.12874065037802826
 Unemployment %:  0.01466801275771702
 Healthcare expenditure %:  0.0536859999556817
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="277">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>alcohol_use_disorders_model, alcohol_use_disorders_scaler <span class="op">=</span> ridge_regression(<span class="st">&#39;alcohol_use_disorders&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mean Squared Error: 0.6783795186517787
Coefficients:
 Year:  0.00228632758024498
 Population density:  -0.11137953739254991
 GDP per capita in USD:  -0.07147970044350507
 Unemployment %:  0.058905857850805404
 Healthcare expenditure %:  0.13540012960196407
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>From the above, we can see that the MSE values for each of the
dependent variables of the study were very small, showing it is a better
model for the data than the linear regression model used previously. We
can now use this model to predict the prevalence of these different
kinds of mental health disorders on more recent global data.</p>
</div>
<div class="cell markdown">
<p>The following extracts all data that is after the period used to
train the ridge regression model (2018 and 2019), and merges all of this
data into a single dataframe.</p>
</div>
<div class="cell code" data-execution_count="278">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>country_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_country_stats.csv&quot;</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>population_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_population_by_year_1950_2023.csv&quot;</span>)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>global_population_data <span class="op">=</span> population_data.melt(id_vars<span class="op">=</span>[<span class="st">&#39;country&#39;</span>], var_name<span class="op">=</span><span class="st">&#39;year&#39;</span>, value_name<span class="op">=</span><span class="st">&#39;population&#39;</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co"># merge both dataframes on the &#39;country&#39; column</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> pd.merge(global_population_data, country_data, on<span class="op">=</span><span class="st">&#39;country&#39;</span>)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="co"># creating &#39;population_density&#39; column</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>density_data[<span class="st">&#39;population_density&#39;</span>] <span class="op">=</span> density_data[<span class="st">&#39;population&#39;</span>] <span class="op">/</span> density_data[<span class="st">&#39;land_area&#39;</span>]</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="co"># typecasting year to correct int</span></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>density_data[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> density_data[<span class="st">&#39;year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows before 2018</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> density_data[(density_data[<span class="st">&#39;year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (density_data[<span class="st">&#39;year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2019</span>)]</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study </span></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> density_data.drop(columns<span class="op">=</span>[<span class="st">&#39;population&#39;</span>, <span class="st">&#39;land_area&#39;</span>, <span class="st">&#39;fertility_rate&#39;</span>, <span class="st">&#39;median_age&#39;</span>, <span class="st">&#39;region&#39;</span>])</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a><span class="co"># renaming &#39;country&#39; to &#39;Country Name&#39; and &#39;year&#39; to &#39;Year&#39;</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>density_data <span class="op">=</span> density_data.rename(columns<span class="op">=</span>{<span class="st">&#39;country&#39;</span>: <span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;year&#39;</span>: <span class="st">&#39;Year&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="279">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/world_country_gdp_usd.csv&quot;</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years before 2018</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data[(gdp_data[<span class="st">&#39;year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (gdp_data[<span class="st">&#39;year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2019</span>)]</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>, <span class="st">&#39;GDP_USD&#39;</span>])</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="co"># renaming &#39;year to &#39;Year&#39;</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>gdp_data <span class="op">=</span> gdp_data.rename(columns<span class="op">=</span>{<span class="st">&#39;year&#39;</span>: <span class="st">&#39;Year&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="280">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/unemployment analysis.csv&quot;</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data.melt(id_vars<span class="op">=</span>[<span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;Country Code&#39;</span>], var_name<span class="op">=</span><span class="st">&#39;Year&#39;</span>, value_name<span class="op">=</span><span class="st">&#39;Unemployment (%)&#39;</span>)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># typecasting year to int </span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">=</span> unemployment_data[<span class="st">&#39;Year&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years before 2018</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data[(unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (unemployment_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2019</span>)]</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>unemployment_data <span class="op">=</span> unemployment_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="281">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> pd.read_csv(<span class="st">&quot;Datasets/life expectancy.csv&quot;</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping rows with years before 2018</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> expenditure_data[(expenditure_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (expenditure_data[<span class="st">&#39;Year&#39;</span>] <span class="op">&lt;=</span> <span class="dv">2019</span>)]</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping irrelevant columns for study </span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>expenditure_data <span class="op">=</span> expenditure_data.drop(columns<span class="op">=</span>[<span class="st">&#39;Country Code&#39;</span>, <span class="st">&#39;Prevelance of Undernourishment&#39;</span>, <span class="st">&#39;CO2&#39;</span>, <span class="st">&#39;Education Expenditure %&#39;</span>, <span class="st">&#39;Corruption&#39;</span>, <span class="st">&#39;Sanitation&#39;</span>, <span class="st">&#39;Injuries&#39;</span>, <span class="st">&#39;Communicable&#39;</span>, <span class="st">&#39;NonCommunicable&#39;</span>, <span class="st">&#39;Unemployment&#39;</span>, <span class="st">&#39;Life Expectancy World Bank&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="282">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list of all dataframes used for merging </span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> [density_data, gdp_data, unemployment_data, expenditure_data]</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co"># using reduce function to merge the dataframes </span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>df_predict <span class="op">=</span> <span class="bu">reduce</span>(<span class="kw">lambda</span> left_df, right_df: pd.merge(left_df, right_df, on<span class="op">=</span>[<span class="st">&#39;Country Name&#39;</span>, <span class="st">&#39;Year&#39;</span>], how<span class="op">=</span><span class="st">&#39;left&#39;</span>), frames)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>df_predict <span class="op">=</span> df_predict.rename(columns<span class="op">=</span>{<span class="st">&#39;Country Name&#39;</span>: <span class="st">&#39;country_name&#39;</span>, <span class="st">&#39;Year&#39;</span>: <span class="st">&#39;year&#39;</span>, <span class="st">&#39;Unemployment (%)&#39;</span>: <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;Region&#39;</span>: <span class="st">&#39;region&#39;</span>, <span class="st">&#39;IncomeGroup&#39;</span>: <span class="st">&#39;income_group&#39;</span>, <span class="st">&#39;Health Expenditure %&#39;</span>: <span class="st">&#39;health_expenditure_%&#39;</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="283">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping all rows from the table with any NaN value </span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>df_predict <span class="op">=</span> df_predict.dropna()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Now that we have a dataframe with countries from the years 2018 and
2019 with all the independent variables we used to train the ridge
regression model, we can now sample some of these countries and predict
which type of mental health disorder would be the most prevalent in that
country. The following function does this:</p>
</div>
<div class="cell code" data-execution_count="285">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function that predicts values for the target based on the model inputted </span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># will be used for each of the different ridge regression models for the mental health disorders </span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_ridge(df, model, scaler, target):</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># extracting necessary columns </span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> df[[<span class="st">&#39;year&#39;</span>, <span class="st">&#39;population_density&#39;</span>, <span class="st">&#39;GDP_per_capita_USD&#39;</span>, <span class="st">&#39;unemployment_%&#39;</span>, <span class="st">&#39;health_expenditure_%&#39;</span>]]</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># scaling the data</span></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>    X_scaled <span class="op">=</span> scaler.transform(X)</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predicting target values </span></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(X_scaled)</span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># adding a column with predicted values to dataframe </span></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>    df[target <span class="op">+</span> <span class="st">&#39;_predicted&#39;</span>] <span class="op">=</span> predictions</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="294">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># taking 5 random samples from the dataframe </span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>predictions_df <span class="op">=</span> df_predict.sample(n<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">40</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="297">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calling predict_ridge for each of the mental health disorders model, and adds the predicted values </span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for each of the sample rows </span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, schizophrenia_model, schizophrenia_scaler, <span class="st">&#39;schizophrenia&#39;</span>)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, eating_disorders_model, eating_disorders_scaler, <span class="st">&#39;eating disorders&#39;</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, anxiety_disorders_model, anxiety_disorders_scaler, <span class="st">&#39;anxiety disorders&#39;</span>)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, drug_use_disorders_model, drug_use_disorders_scaler, <span class="st">&#39;drug use disorders&#39;</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, depression_model, depression_scaler, <span class="st">&#39;depression&#39;</span>)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predict_ridge(predictions_df, alcohol_use_disorders_model, alcohol_use_disorders_scaler, <span class="st">&#39;alcohol use disorders&#39;</span>)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>predictions</span></code></pre></div>
<div class="output execute_result" data-execution_count="297">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_name</th>
      <th>year</th>
      <th>population_density</th>
      <th>GDP_per_capita_USD</th>
      <th>unemployment_%</th>
      <th>region</th>
      <th>income_group</th>
      <th>health_expenditure_%</th>
      <th>schizophrenia_predicted</th>
      <th>eating disorders_predicted</th>
      <th>anxiety disorders_predicted</th>
      <th>drug use disorders_predicted</th>
      <th>depression_predicted</th>
      <th>alcohol use disorders_predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>64</th>
      <td>Estonia</td>
      <td>2018</td>
      <td>31.190092</td>
      <td>23063.563820</td>
      <td>5.37</td>
      <td>Europe &amp; Central Asia</td>
      <td>High income</td>
      <td>6.686428</td>
      <td>0.219950</td>
      <td>0.305245</td>
      <td>4.186930</td>
      <td>0.923014</td>
      <td>3.487352</td>
      <td>1.565228</td>
    </tr>
    <tr>
      <th>353</th>
      <td>Luxembourg</td>
      <td>2019</td>
      <td>239.371815</td>
      <td>113218.713300</td>
      <td>5.59</td>
      <td>Europe &amp; Central Asia</td>
      <td>High income</td>
      <td>5.370760</td>
      <td>0.337526</td>
      <td>0.910579</td>
      <td>6.964158</td>
      <td>1.887979</td>
      <td>4.090488</td>
      <td>1.100371</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Bosnia and Herzegovina</td>
      <td>2018</td>
      <td>66.669196</td>
      <td>6070.352980</td>
      <td>18.40</td>
      <td>Europe &amp; Central Asia</td>
      <td>Upper middle income</td>
      <td>8.891460</td>
      <td>0.193708</td>
      <td>0.231242</td>
      <td>3.950223</td>
      <td>0.822857</td>
      <td>3.444407</td>
      <td>1.875561</td>
    </tr>
    <tr>
      <th>283</th>
      <td>Croatia</td>
      <td>2019</td>
      <td>73.798284</td>
      <td>15311.766900</td>
      <td>6.62</td>
      <td>Europe &amp; Central Asia</td>
      <td>High income</td>
      <td>6.978618</td>
      <td>0.209166</td>
      <td>0.255245</td>
      <td>3.949089</td>
      <td>0.842618</td>
      <td>3.432326</td>
      <td>1.616733</td>
    </tr>
    <tr>
      <th>211</th>
      <td>Tonga</td>
      <td>2018</td>
      <td>146.041667</td>
      <td>4740.700272</td>
      <td>3.07</td>
      <td>East Asia &amp; Pacific</td>
      <td>Upper middle income</td>
      <td>5.054817</td>
      <td>0.193956</td>
      <td>0.156447</td>
      <td>3.400137</td>
      <td>0.689381</td>
      <td>3.312442</td>
      <td>1.505658</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>From this, we are able to see the different predicted values for the
prevalence of schizophrenia, eating disorders, anxiety disorders, drug
use disorders, and alcohol use disorders for each of the five random
rows from the dataframe, having data from 2018 and 2019.</p>
</div>
<div class="cell markdown">
<p><strong>Closing Remarks</strong></p>
<p>This project aimed to analyze the correlation between various social
and economic factors (population density, GDP per capita, unemployment
percenatge, and healthcare expenditure) and the prevalence of mental
health disorders throughout a country (schizophrenia, eating disorders,
anxiety disorders, drug use disorders, depression, and alcohol use
disorders). Utilizing advanced regression techniques, such as Ridge
Regression, allowed for a complex and comprehensive analysis of these
correlations. There are a broad array of implications from this study,
as it can be used to help identify some non-traditional predictors of
mental health disorders within certain countries. This will ultimately
enable policymakers, researchers, healthcare providers, and more with
the abilities to develop policies and interventions addressing these
issues within their respective countries and regions. This study can
ultimately lead to more improved resource allocations for mental health
outcomes, benefitting many countries around the world.</p>
</div>
</body>
</html>
